#!/bin/bash

# All-in-one script for Qwen3-VL-8B benchmarking
# This script:
# 1. Runs inference on images to generate predictions
# 2. Evaluates predictions against ground truth
# 3. Saves evaluation results to a file

# ========== CONSTANTS ==========

# vLLM server configuration
VLLM_BASE_URL="${VLLM_BASE_URL:-http://localhost:8000/v1}"

# Model configuration
MODEL_NAME="${MODEL_NAME:-Qwen/Qwen3-VL-8B-Instruct}"
MODEL_SHORT_NAME="qwenvl"  # Short name for output files (e.g., ds, dpsk, internvl, qwenvl)

# Data directories
DATA_ROOT="${DATA_ROOT:-./data}"
DATA_DIR="$DATA_ROOT/longbenchv2_img/images"

# Output directories
PRED_DIR="$DATA_ROOT/pred/${MODEL_SHORT_NAME}"
RESULT_DIR="./results"

# Ground truth file (text ground truth in OmniDocBench format)
# This file should be generated by the render CLI with --text-gt-output parameter
GT_FILE="$DATA_ROOT/longbenchv2_img/text_ground_truth.jsonl"

# Evaluation result file
RESULT_FILE="$RESULT_DIR/${MODEL_SHORT_NAME}_evaluation.json"

# Inference configuration
MAX_WORKERS="${MAX_WORKERS:-32}"
PRESENCE_PENALTY="${PRESENCE_PENALTY:-0.0}"

# Conda environment
CONDA_ENV="${CONDA_ENV:-test}"

# ========== FUNCTIONS ==========

log_info() {
    echo -e "\033[1;34m[INFO]\033[0m $1"
}

log_success() {
    echo -e "\033[1;32m[SUCCESS]\033[0m $1"
}

log_error() {
    echo -e "\033[1;31m[ERROR]\033[0m $1"
}

log_section() {
    echo ""
    echo "========================================"
    echo "$1"
    echo "========================================"
}

# ========== MAIN SCRIPT ==========

log_section "Qwen3-VL-8B Benchmarking Pipeline"

log_info "Configuration:"
log_info "  Model: $MODEL_NAME"
log_info "  Data directory: $DATA_DIR"
log_info "  Prediction directory: $PRED_DIR"
log_info "  Ground truth file: $GT_FILE"
log_info "  Result file: $RESULT_FILE"
log_info "  Max workers: $MAX_WORKERS"
log_info "  Presence penalty: $PRESENCE_PENALTY"

# Step 1: Check prerequisites
log_section "Step 1: Checking Prerequisites"

if [ ! -d "$DATA_DIR" ]; then
    log_error "Data directory not found: $DATA_DIR"
    log_error "Please run the render CLI first to generate images and ground truth"
    exit 1
fi

if [ ! -f "$GT_FILE" ]; then
    log_error "Ground truth file not found: $GT_FILE"
    log_error "Please run the render CLI with --text-gt-output parameter first"
    exit 1
fi

log_success "Prerequisites check passed"

# Step 2: Run inference
log_section "Step 2: Running Inference"

# Create prediction directory
mkdir -p "$PRED_DIR"

log_info "Running inference with $MODEL_NAME..."
micromamba run -n "$CONDA_ENV" python scripts/ocr/Qwen3-VL-8B_img2md.py \
    --input "$DATA_DIR" \
    --output "$PRED_DIR" \
    --base_url "$VLLM_BASE_URL" \
    --model_name "$MODEL_NAME" \
    --max_workers "$MAX_WORKERS" \
    --presence_penalty "$PRESENCE_PENALTY"

if [ $? -ne 0 ]; then
    log_error "Inference failed"
    exit 1
fi

log_success "Inference completed successfully"

# Step 3: Run evaluation
log_section "Step 3: Running Evaluation"

# Create result directory
mkdir -p "$RESULT_DIR"

log_info "Evaluating predictions against ground truth..."
micromamba run -n robust_ocm python -m robust_ocm.eval \
    --gt "$GT_FILE" \
    --pred "$PRED_DIR" \
    --output "$RESULT_FILE"

if [ $? -ne 0 ]; then
    log_error "Evaluation failed"
    exit 1
fi

log_success "Evaluation completed successfully"

# Final summary
log_section "Benchmarking Pipeline Completed"

log_info "Results:"
log_info "  Predictions saved to: $PRED_DIR"
log_info "  Evaluation results saved to: $RESULT_FILE"

log_success "All done!"