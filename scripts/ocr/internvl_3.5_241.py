"""
InternVL3.5-8B OCR inference script with concurrent processing.

To start vLLM server with data parallelism for InternVL3.5-8B:

# Single GPU:
vllm serve OpenGVLab/InternVL3_5-8B \
    --host 0.0.0.0 \
    --port 8000 \
    --dtype auto \
    --trust-remote-code

# Multiple GPUs (data parallelism):
vllm serve OpenGVLab/InternVL3_5-8B \
    --host 0.0.0.0 \
    --port 8000 \
    --data-parallel-size 4 \
    --dtype auto \
    --trust-remote-code

Then run this script:
micromamba run -n test python ./scripts/ocr/internvl_3.5_241.py \
    --input data/longbenchv2_img/images \
    --output data/pred/internvl \
    --base_url http://localhost:8000/v1 \
    --model_name OpenGVLab/InternVL3_5-8B \
    --max_workers 32
"""

from openai import OpenAI, APIConnectionError
import os
import base64
import concurrent.futures
import argparse
from tqdm import tqdm  # Áî®‰∫éÊòæÁ§∫ËøõÂ∫¶Êù°

def encode_image(image_path):
    """Â∞ÜÊú¨Âú∞ÂõæÁâáËΩ¨Êç¢‰∏∫base64ÁºñÁ†Å"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def process_single_image(image_info, prompt_text, client, output_dir, model_name, presence_penalty):
    """Â§ÑÁêÜÂçïÂº†ÂõæÁâáÁöÑÂáΩÊï∞"""
    image_file, image_dir = image_info
    image_path = os.path.join(image_dir, image_file)

    # Ê£ÄÊü•ËæìÂá∫Êñá‰ª∂ÊòØÂê¶Â∑≤Â≠òÂú®
    base_name = os.path.splitext(image_file)[0]
    output_path = os.path.join(output_dir, base_name + ".md")
    if os.path.exists(output_path):
        return f"‚è≠ Ë∑≥ËøáÂ∑≤Â≠òÂú®: {image_file}"

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt_text
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{encode_image(image_path)}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=8192,
            timeout=300,
            presence_penalty=presence_penalty,
        )

        content = response.choices[0].message.content

        with open(output_path, "w", encoding='utf-8') as f:
            print(content, file=f)

        return f"‚úì ÊàêÂäüÂ§ÑÁêÜ: {image_file}"
    except APIConnectionError as e:
        return f"‚úó ËøûÊé•Ë∂ÖÊó∂: {image_file}, ÈîôËØØ: {str(e)}"
    except Exception as e:
        return f"‚úó Â§ÑÁêÜÂ§±Ë¥•: {image_file}, ÈîôËØØ: {str(e)}"

def process_images(image_dir, prompt_text, client, output_dir, model_name, presence_penalty, max_workers=32):
    """Â§ÑÁêÜÁõÆÂΩï‰∏≠ÁöÑÊâÄÊúâÂõæÁâáÂπ∂‰∏∫ÊØè‰∏™ÂõæÁâáÁîüÊàêÂçïÁã¨ÁöÑMarkdownÊñá‰ª∂ÔºàÂ§öÁ∫øÁ®ãÁâàÊú¨Ôºâ"""

    # ËÆæÁΩÆËæìÂá∫ÁõÆÂΩïÔºåÈªòËÆ§‰∏∫ÂõæÁâáÁõÆÂΩï
    if output_dir is None:
        output_dir = image_dir
    else:
        os.makedirs(output_dir, exist_ok=True)

    # Ëé∑ÂèñÂõæÁâáÊñá‰ª∂ÂàóË°®ÔºàÊîØÊåÅÂ∏∏ËßÅÊ†ºÂºèÔºâ
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp']
    image_files = [f for f in os.listdir(image_dir)
                  if os.path.isfile(os.path.join(image_dir, f)) and
                  any(f.lower().endswith(ext) for ext in image_extensions)]

    if not image_files:
        print("ÊåáÂÆöÁõÆÂΩï‰∏≠Ê≤°ÊúâÊâæÂà∞ÂõæÁâáÊñá‰ª∂")
        return

    print(f"ÊâæÂà∞ {len(image_files)} ‰∏™ÂõæÁâáÊñá‰ª∂ÔºåÂºÄÂßãÂ§ÑÁêÜ...")

    # ÂáÜÂ§áÂèÇÊï∞ÂàóË°®
    image_infos = [(img_file, image_dir) for img_file in image_files]

    # ‰ΩøÁî®Á∫øÁ®ãÊ±†Âπ∂ÂèëÂ§ÑÁêÜ
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Êèê‰∫§ÊâÄÊúâ‰ªªÂä°
        futures = {
            executor.submit(process_single_image, info, prompt_text, client, output_dir, model_name, presence_penalty): info[0]
            for info in image_infos
        }

        # ‰ΩøÁî®tqdmÊòæÁ§∫ËøõÂ∫¶Êù°
        results = []
        for future in tqdm(concurrent.futures.as_completed(futures), total=len(image_files), desc="Â§ÑÁêÜÂõæÁâá"):
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                results.append(f"‚úó ÂºÇÂ∏∏: {str(e)}")

    # ÊâìÂç∞Â§ÑÁêÜÁªìÊûúÊëòË¶Å
    completed_count = sum(1 for r in results if "‚úì ÊàêÂäüÂ§ÑÁêÜ" in r)
    failed_count = sum(1 for r in results if "‚úó" in r)
    skipped_count = sum(1 for r in results if "‚è≠ Ë∑≥ËøáÂ∑≤Â≠òÂú®" in r)
    print(f"\nÂ§ÑÁêÜÂÆåÊàêÁªüËÆ°:")
    print(f"‚úì ÊàêÂäüÂ§ÑÁêÜ: {completed_count} ‰∏™")
    print(f"‚è≠ Ë∑≥ËøáÂ∑≤Â≠òÂú®: {skipped_count} ‰∏™")
    print(f"‚úó Â§ÑÁêÜÂ§±Ë¥•: {failed_count} ‰∏™")
    print(f"üìÅ ÊÄªÂÖ±: {len(image_files)} ‰∏™Êñá‰ª∂")
    print(f"ÁªìÊûú‰øùÂ≠òÂú®: {output_dir}")

    # Â¶ÇÊûúÊúâÂ§±Ë¥•ÁöÑ‰ªªÂä°ÔºåÊâìÂç∞ËØ¶ÁªÜ‰ø°ÊÅØ
    if failed_count > 0:
        print("\nÂ§±Ë¥•ËØ¶ÊÉÖ:")
        for result in results:
            if "‚úó" in result:
                print(f"  - {result}")

# ‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="InternVL OCR inference with local vLLM backend")
    parser.add_argument('--input', '-i', type=str, required=True, help='Input directory containing images')
    parser.add_argument('--output', '-o', type=str, required=True, help='Output directory for OCR results')
    parser.add_argument('--base_url', type=str, default='http://localhost:8000/v1', help='API base URL')
    parser.add_argument('--api_key', type=str, default=None, help='API key (optional for local vLLM)')
    parser.add_argument('--model_name', type=str, default='OpenGVLab/InternVL3_5-8B', help='Model name')
    parser.add_argument('--max_workers', type=int, default=32, help='Number of concurrent workers')
    parser.add_argument('--presence_penalty', type=float, default=0.0, help='Presence penalty for repetition control (0.0 to 2.0)')

    args = parser.parse_args()

    # ÂàõÂª∫OpenAIÂÆ¢Êà∑Á´Ø
    client = OpenAI(
        base_url=args.base_url,
        api_key=args.api_key if args.api_key else "dummy",
    )

    # OCR Prompt
    PROMPT_TEXT = r"""
    You are an AI assistant specialized in converting PDF images to Markdown format. Please follow these instructions for the conversion:

        1. Text Processing:
        - Accurately recognize all text content in the PDF image without guessing or inferring.
        - Convert the recognized text into Markdown format.
        - Maintain the original document structure, including headings, paragraphs, lists, etc.

        2. Mathematical Formula Processing:
        - Convert all mathematical formulas to LaTeX format.
        - Enclose inline formulas with \( \). For example: This is an inline formula \( E = mc^2 \)
        - Enclose block formulas with \[ \]. For example: \[ \frac{-b \pm \sqrt{b^2 - 4ac}}{2a} \]

        3. Table Processing:
        - Convert tables to HTML format.
        - Wrap the entire table with <table> and </table>.

        4. Figure Handling:
        - Ignore figures content in the PDF image. Do not attempt to describe or convert images.

        5. Output Format:
        - Ensure the output Markdown document has a clear structure with appropriate line breaks between elements.
        - For complex layouts, try to maintain the original document's structure and format as closely as possible.

        Please strictly follow these guidelines to ensure accuracy and consistency in the conversion. Your task is to accurately convert the content of the PDF image into Markdown format without adding any extra explanations or comments.
    """

    # Â§ÑÁêÜÂõæÁâá
    process_images(
        args.input,
        PROMPT_TEXT,
        client,
        args.output,
        args.model_name,
        args.presence_penalty,
        args.max_workers
    )